data:
  dataset_card: lbox/lbox_open
  training_set_name: train
  validation_set_name: validation
  test_set_name: test
  use_local_data: false
  path_train:
  path_valid:
  path_test:

model:
  decoder_max_length: 1024
  input_template_type: 0
  model_type: generative
  max_seq_length: 768
  task: summarization
  subtask: summarization
  target_field: precedent
  target_parses_dict:
    summarization:
      - summarization
  path_template:
  plm:
    freeze: false
    eval_mode: false
    name: legal-gpt
    path: lbox/lcube-base
    revision:
  precision: 32

train:
  accelerator: auto
  accumulate_grad_batches: 2
  limit_val_batches: 1.0
  batch_size: 6
  batch_size_prediction: 12
  check_val_every_n_epoch: 2
  fast_dev_run: false
  max_epochs: 20
  multiple_trainloader_mode:
  seed: 1
  strategy: null
  weight:
    trained: false
    path:
    save_path_dir: ./data/models
    do_not_load_pretrained_weight: false
    old_format: false
  log_dir: ./logs
  optim:
    gradient_clip_val: 1.0
    gradient_clip_algorithm: norm
    prompt:
      lr: 0.1
      optimizer_type: adamw
      lr_scheduler_type: warmup_constant
      lr_scheduler_param:
        warmup_constant:
          num_warmup_steps: 10
    plm:
      lr: 0.0001
      optimizer_type: adamw
    swa:
      use: false
      lr: 0.00005
      swa_epoch_start: 4
      annealing_epochs: 6
  profiler: null
  num_sanity_val_steps: 0
  val_check_interval: 0.5
  validation_metric: em
  validation_target_parse: statute_classification
  validation_sub_param:
    method: text_em
    target_sub_parse:

infer:
  max_length:
  max_new_tokens: 256
  min_length: 5
  temperature: 1.0
  do_sample: False
  top_k: 0
  top_p: 0.9
  repetition_penalty: 1.0
  num_beams: 1
  bad_words_ids: null
  parse_sep_token: "*"
  value_sep_token: "|"
  empty_token: "없음"

  